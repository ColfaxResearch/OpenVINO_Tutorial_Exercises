{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Simple Inference\n",
    "\n",
    "In this exercise, you will be running inference on a few images.\n",
    "The primary goal of the first exercise is to familiarize you with the workflow for inference.\n",
    "\n",
    "You will be creating a vehicle detection application where the model counts how many vehicles are found in an image. The image you will use is:\n",
    "\n",
    "<img src=\"cars_1900_first_frame.jpg\">\n",
    "\n",
    "There appears to be 9 vehicles in the image. Let's see how the computer vision models do.\n",
    "\n",
    "### Important! The quiz will ask you how many vehicles were detected in the last step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Converting the Model\n",
    "\n",
    "The first step is to get some compute vision models to use for the inference.\n",
    "For this exercise,you will be using the following two models available from Model Downloader:\n",
    "\n",
    "- `mobilenet-ssd`\n",
    "- `vehicle-detection-adas-0002`\n",
    "\n",
    "First, start with the `mobilenet-ssd`.\n",
    "As the model downloader interface is terminal commands, the jupyter cell needs to be converted to run terminal commands (bash) by adding %%bash at the top.\n",
    "The following cell has been populated with the downloader showing the help command. \n",
    "\n",
    "Modify the cell to download the `mobilenet-ssd` model.\n",
    "\n",
    "Notes:\n",
    "- You can download the model to anywhere you would like. But remember the path to the models, as you will need it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mobilenet-ssd` model is a caffe model, so it needs to be converted to IR format. Furthermore, the scaling and the mean values must be set so that the network can take RGB images without needing to scale it in separate preprocessing code. \n",
    "\n",
    "These values should come from your expected dataset. For example if you are getting images from security cameras, the mean value should be the time average pixel value of your camera. But for this example set scale to 256 and mean values to \\[127,127,127\\].\n",
    "\n",
    "Modify the following cell to convert the `mobilenet-ssd model` to IR format, with the image scale of 256 and image mean value of \\[127,127,127\\].\n",
    "\n",
    "Notes:\n",
    "- You can place the IR file anywhere but make sure to take note of the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/opt/intel/openvino/deployment_tools/model_optimizer/mo.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the `vehicle-detection-adas-0002`.\n",
    "In addition to the raw models like the `mobilenet-ssd`, model downloader has a number of models that are already converted to the IR format. \n",
    "`vehicle-detection-adas-0002` turns out to be one of them (in fact, this model is based on the same base network, mobilenet).\n",
    "So for this model, you simply need to download it.\n",
    "\n",
    "\n",
    "Modify the cell to download the `vehicle-detection-adas-0002` model.\n",
    "\n",
    "Notes:\n",
    "- Once again, you can place the IR file anywhere but make sure to take note of the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You now have the models needed to run inference.\n",
    "\n",
    "## Step 2: Running Inference\n",
    "\n",
    "Next step is running the inference itself.\n",
    "This section will make use of the Inference Engine that we have covered. \n",
    "If you get stuck on any of the stps, refer to the slide deck from course 1 video 6.\n",
    "\n",
    "First things first, run the following cell to import all the necessary Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os                         \n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating the `IENetwork` objects.\n",
    "\n",
    "Complete the following cell by creating `IENetwork` object for `mobilenet-ssd` model. You will need the path to the IR files from the earlier steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create IENetwork object for mobilenet-ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is the `IECore` object. \n",
    "\n",
    "It turns out that the network has some layers that require a CPU extension. \n",
    "This can be verified using the result of query_network method of `IECore`, though you can skip this step in this exercise.\n",
    "The required extension is one that is provided by the toolkit.\n",
    "\n",
    "Complete the following cell by creating an `IECore` object, and add the specified `extension` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for preprocessing. \n",
    "\n",
    "The input image will be loaded using OpenCV, so several image processing steps needs to be done.\n",
    "First, it will have the wrong size. so the image must be reshaped using `cv2.resize()` function.\n",
    "Second, OpenCV loads an image in HWC format whereas the network expects an NCHW format. \n",
    "So the image must first be transposed using `transpose()` method of numpy arrays. \n",
    "Then the N dimention must be added using the `reshape()` method.\n",
    "\n",
    "As the preprocesisng is outside of the toolkit, they are already implemented for you.\n",
    "However it is missing the sizes for dimensions NCHW of the network input.\n",
    "\n",
    "Complete the `prepImage()` function by getting the values for `n`, `c`, `h` and `w` from the function input `net`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares image for imference\n",
    "# inputs:\n",
    "#     orig_image - numpy array containing the original, unprocessed image\n",
    "#     net        - IENetwork object\n",
    "# output: \n",
    "#     preprocessed image.\n",
    "def prepImage(orig_image, net):\n",
    "    \n",
    "    ##! Find n, c, h, w from net !##\n",
    "    \n",
    "    # Resize the data to the input H and W\n",
    "    input_image = cv2.resize(orig_image, (w, h))\n",
    "    # Change the dimensions. old dim 2 -> new dim 0, old dim 0 -> new dim 1, and old dim 1 -> new dim 2\n",
    "    input_image = input_image.transpose((2, 0, 1))\n",
    "    # Add the N dimension\n",
    "    input_image.reshape((n, c, h, w))\n",
    "\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the postprocessing. \n",
    "\n",
    "`mobilenet-ssd` returns 100 potential regions where an object might be.\n",
    "For every potential object, the model assigns a probability that it is an object.\n",
    "So to find the vehicles in the image, you need to look for entries over a certain threshold probability.\n",
    "The model also provides bounding boxes for where the potential object is, and it returns an index to the detected object.\n",
    "All this information can be processed and placed on the original image.\n",
    "\n",
    "Postprocessing, however, is also outside of the toolkit.\n",
    "So this step has already been implemented for you, and no modification is required.\n",
    "The function takes in the numpy array result of the network (not the dictionary result) and the original image (before preprocessing). \n",
    "Additionally, the function set the object likelihood threshold to 50% but this can be overridden with `prob_threshold` argument.\n",
    "\n",
    "Study the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes the result. Prints the number of detected vehices and paints rectangles around the vehicles.\n",
    "# inputs:\n",
    "#    detected_obects - numpy array containing the ooutput of the model\n",
    "#    orig_image      - numpy array containing the original, unprocessed image\n",
    "#    prob_threashold - Required probability for \"detection\"\n",
    "# output:\n",
    "#    numpy array of image wtth rectangles drawn around the vehicles.\n",
    "def showResult(detected_objects, orig_image, prob_threshold=0.5):\n",
    "    initial_w = orig_image.shape[1]\n",
    "    initial_h = orig_image.shape[0]\n",
    "    out_frame = orig_image.copy()\n",
    "    \n",
    "    detected_count = 0\n",
    "    for obj in detected_objects[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > prob_threshold:\n",
    "            xmin = int(obj[3] * initial_w)\n",
    "            ymin = int(obj[4] * initial_h)\n",
    "            xmax = int(obj[5] * initial_w)\n",
    "            ymax = int(obj[6] * initial_h)\n",
    "            class_id = int(obj[1])\n",
    "            # Draw box and label\\class_id\n",
    "            color = (255,255,255)\n",
    "            cv2.rectangle(out_frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            cv2.putText(out_frame, str(round(obj[2] * 100, 1)) + ' %', (xmin, ymin - 7), cv2.FONT_HERSHEY_COMPLEX, 0.6, color, 1)\n",
    "            detected_count+=1\n",
    "    print(\"{} vehicles detected.\".format(detected_count))\n",
    "    fig = plt.figure(dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(cv2.cvtColor(out_frame, cv2.COLOR_BGR2RGB), interpolation='none')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    del out_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to put everything together and run an inference workload on an image. \n",
    "\n",
    "An image has been provided to you, but you need to preprocess it using the `prepImage()` function from earlier. It takes the raw image as well as the IENetwork you created earlier.\n",
    "Hint: Be sure not to overwrite the original image, as you will need it for `showResults()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"cars_1900_first_frame.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "# Preprocess the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an ExecutableNetwork object for CPU device using the IENetwork object for `mobilenet-ssd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ExecutableNetwork object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the inference in the synchronous mode. Remember that you will need the name of the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need the name of input layer. There is only one input layer.\n",
    "\n",
    "# Run synchronous inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, process the result by running the `showResult()` function. Note that this function  accepts an array result, so you need to extact the array from the dictionary result of the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need the name of output layer. There is only one output layer.\n",
    "\n",
    "# Run showResult. Make sure you extracted the array result from the dictionary returned by the inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully run a computer vision application with the toolkit. This workload was done on the CPU, so now let's try it on other devices.\n",
    "\n",
    "## Step 3: Using the job queue and the DevCloud\n",
    "\n",
    "Next we will look at how to run inference on other types of nodes. \n",
    "But to do this, we need to discuss the job queue feature.\n",
    "\n",
    "DevCloud relies on a job queue to give fair access to the available resources.\n",
    "Users can submit \"jobs\" to the queue and request a certain type of node (e.g. system with VPU) to complete the task.\n",
    "The job scheduler will then take the job and execute it on the first available system of that type.\n",
    "In addition to special hardware type, the jobs on nodes will have far more resources in terms of RAM and CPU than this Jupyter notebook. \n",
    "So any workload beyond simple testing should be executed through the job queue.\n",
    "\n",
    "The resource manager used in the DevCloud is called PBS Torque, and you can interact with it using commands prefixed with 'q'.\n",
    "The DevCloud website has instructions on how to use these tools.\n",
    "For this course however, the commands are provided to you.\n",
    "\n",
    "The main difference for the purpose of this exercise is that you can not simply \"run\" jupyter cells on the queue.\n",
    "Instead you need to create python files to be executed.\n",
    "In jupyter, cells beginning with `%%writefile myfile.txt` will dump the contents of the cell into a file, named myfile.txt in this case.\n",
    "Below cell has an incomplete `main.py` file for running the same workload.\n",
    "\n",
    "The instructions for completing the file is broken into steps. \n",
    "In the cell, the parts that need to be modified is signified by `##! ... !##`\n",
    "The number in parenthesis shows the step in the instruction that this corresponds to.\n",
    "Follow the instructions to complete `main.py`. (Hint: most of these should be a simple copy and paste from earlier cells)\n",
    "\n",
    "*(2.1)* Complete the `prepImage()` function by finding the NCHW values from the network. \n",
    "\n",
    "*(2.2)* Create IENetwork models for `vehicle-detection-adas-0002`. \n",
    "\n",
    "*(2.3)* Create IECore object and load the extension. Optional: in this script, the device to use is an user input and is stored in `device` variable. Add an if check to see if `device` includes CPU. With that said, it is safe to load the CPU extension even if we do not use CPU for the inference. \n",
    "\n",
    "*(2.4)* Preprocess the image with `prepImage()`.\n",
    "\n",
    "*(2.5)* Create an ExecutableNetwork object. IENetwork should be the one created earlier, and the device should be the one in `device` variable. This variable is set by the commandline input to the main.py script.\n",
    "\n",
    "*(2.6)* Run synchronous inference. Remember that you will need the name of the input layer.\n",
    "\n",
    "*(2.7)* Run printCount. This is the equivalent of showResult from earlier, but does not show the image. Remember that you need the output layer name. \n",
    "\n",
    "Side Note: Jobs that we submit to job queues will not have HTML outputs, so this example simply prints the number of detected cars. If you need the image, you will need to write it into a file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "import os\n",
    "import sys\n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "import cv2\n",
    "\n",
    "# Prepares image for imference\n",
    "# inputs:\n",
    "#     orig_image - numpy array containing the original, unprocessed image\n",
    "#     net        - IENetwork object\n",
    "# output: \n",
    "#     preprocessed image.\n",
    "def prepImage(orig_image, net):\n",
    "    \n",
    "    ##! (2.1) Find n, c, h, w from net !##\n",
    "    \n",
    "    input_image = cv2.resize(orig_image, (w, h))\n",
    "    input_image = input_image.transpose((2, 0, 1))\n",
    "    input_image.reshape((n, c, h, w))\n",
    "    return input_image\n",
    "\n",
    "# Processes the result. Prints the number of detected vehices.\n",
    "# inputs:\n",
    "#    detected_obects - numpy array containing the ooutput of the model\n",
    "#    prob_threashold - Required probability for \"detection\"\n",
    "# output:\n",
    "#    numpy array of image wtth rectangles drawn around the vehicles.\n",
    "def printCount(detected_objects, prob_threshold=0.5):\n",
    "    detected_count = 0\n",
    "    for obj in detected_objects[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > prob_threshold:\n",
    "            detected_count+=1    \n",
    "    print(\"{} vehicles detected.\".format(detected_count))\n",
    "\n",
    "# Getting the device as commandline argument\n",
    "device = sys.argv[1]\n",
    "    \n",
    "##! (2.2) create IENetwork object for vehicle-detection-adas-0002 !##\n",
    "\n",
    "##! (2.3) create IECore object and load the following extension !##\n",
    "extension = '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so'\n",
    "\n",
    "image_path = \"cars_1900_first_frame.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "\n",
    "##! (2.4) Preprocess the image. !##\n",
    "\n",
    "##! (2.5) Create ExecutableNetwork object. Use the device variable for targetted device !##\n",
    "\n",
    "##! (2.6) Run synchronous inference. !##\n",
    "\n",
    "##! (2.7) Run printCount. Make sure you extracted the array result form the dictionary returned by infer(). !##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the script, you are ready to submit this workload to the queue.\n",
    "\n",
    "Once in the queue, the workload will be executed on a remote system and the output is returned to you in a file.\n",
    "This process can take some time, so we have provided an utility function that automatically waits for completion.\n",
    "The details of this function are not directly relevant to the exercise, but you can find the code in [notebook_utils.py](notebook_utils.py)\n",
    "\n",
    "Jobs are submitted through the `qsub` command, and the command you need is provided in the following cell.\n",
    "For the purposes of this lab, there are two important details.\n",
    "One is the command in the quotes, `python3 main.py CPU` is the command that is executed on the system.\n",
    "The second is the `-l` flag that specifies what type of node the job requests.\n",
    "If you want to learn more about using the DevCloud queue, go to the DevCloud documentation page.\n",
    "\n",
    "Run the following cell to run the job on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import waitForJob\n",
    "job_name = !echo \"python3 main.py CPU\" | qsub -d `pwd` -N objdet -l nodes=1:skylake\n",
    "print(\"Job submitted. Waiting for output. This may take some time.\")\n",
    "waitForJob(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the following cell to run the job on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = !echo \"python3 main.py GPU\" | qsub -d `pwd` -N objdet -l nodes=1:skylake:intel-hd-530\n",
    "print(\"Job submitted. Waiting for output. This may take some time.\")\n",
    "waitForJob(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully run the inference workload on a GPU and a CPU. \n",
    "\n",
    "## Step 4: Quiz question\n",
    "\n",
    "For the final step, let's try lowering the required confidence to 0.01 (e.g. 1%) and see how many vehicles are detected by the model. \n",
    "You will have to go back to the `main.py` cell, and add `prob_threshold` argument to `printCount` function.\n",
    "**The quiz will ask you how many vehicles were detected by the vehicle-detection-adas-0002 at this setting.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
