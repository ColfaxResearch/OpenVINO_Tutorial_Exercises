{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Multiple Requests and Callbacks\n",
    "\n",
    "In this exercise, you will implement inference with multiple requests using callbacks. \n",
    "\n",
    "The workload will be once again vehicle detection, but on a video this time. \n",
    "Specifically, your application will count the cars in the frame and report three metrics: maximum number of cars in one frame, minimum number of cars in one frame, and average number of cars in all frames.\n",
    "Run the fllowing cell to see the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "!ln -sf /data/reference-sample-data/object-detection-python/cars_1900.mp4 \n",
    "HTML(\"<video alt=\\\"\\\" controls autoplay height=\\\"480\\\"><source src=\\\"cars_1900.mp4\\\" type=\\\"video/mp4\\\" /></video>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important! The quiz will ask you how the average number of vehicles detected in the last step.\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The video course covered some potential implementations using the `wait()` function, including the zero timeout wait.\n",
    "While the zero timeout example in the video works well, it goes through all the requests over and over again until one of them is done.\n",
    "In this exercise, you will implement multiple inference that simply waits for the first finished slot using Python queues and inference callbacks\n",
    "\n",
    "Python queues have couple of interesting features that make them work well with the multiple request inference workload.\n",
    "One is that Python queues are thread-safe. \n",
    "WIthout going in to too much detail, this means that the queue is safe to use in an asynchronous setting, like our requests.\n",
    "The second feature is the `get()` function (the \"pop\" function).\n",
    "If the queue is empty when `get()` is called, it will wait until an item becomes available.\n",
    "\n",
    "The trick is to have a queue of *available request slots* that the main loop waits for, so that the main loop can wait on the queue instead of checking for the status of every slot.\n",
    "When individual requests are done, they will need to add their own slot id number to the queue.\n",
    "This is where we take advantage of the callback function, which is called right when an inference is completed.\n",
    "\n",
    "## (Optional) Step 0: Python queue\n",
    "\n",
    "This section is designed to give you a brief introduction to Python queue. \n",
    "If you are already familiar, skip to step 1.\n",
    "\n",
    "Python queue are data structures that are accessed in First In First Out (FIFO) order.\n",
    "When used in an asynchrnous workload, this can be used to access the jobs as they complete.\n",
    "\n",
    "The following is a brief example of using queue in an asynchronous setting.\n",
    "This example uses threading instead of inference engine so to keep the example simple.\n",
    "Each thread sleeps for some time, and then puts a tuple containing the id of the thread and how long it slept for.\n",
    "The main thread will wait on the queue, and print out the contents of the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Sample asynchronous workload that simply sleeps, and then places ID in queue\n",
    "def foo(q, myid, timeout):\n",
    "    time.sleep(timeout)\n",
    "    q.put((myid, timeout))\n",
    "\n",
    "# Creating the queue for completed tasks\n",
    "completion_queue = queue.Queue()\n",
    "\n",
    "# Create and start two tasks\n",
    "t1 = threading.Thread(target=foo, args=(completion_queue, 1, 3))\n",
    "t2 = threading.Thread(target=foo, args=(completion_queue, 2, 1))\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Print tasks as they complete\n",
    "completed_id, timeout = completion_queue.get()\n",
    "print(\"task {} completed after sleeping for {} second(s)\".format(completed_id, timeout))\n",
    "completed_id, timeout = completion_queue.get()\n",
    "print(\"task {} completed after sleeping for {} second(s)\".format(completed_id, timeout))\n",
    "\n",
    "\n",
    "# Confirming the threads are completed. Not necessary, but good practice.\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the task 2 had a shorter timeout and completed first, and it was printed immediately without waiting for task 1 to complete.\n",
    "Additionally, notice that I did not have to specify any id in the `get()` function.\n",
    "We will adapt this for inference engine\n",
    "\n",
    "\n",
    "## Step 1: Downloading model\n",
    "\n",
    "We will once again use the `vehicle-detection-adas-0002` model.\n",
    "Using the model downloader, download the FP32 and FP16 versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Helper functions\n",
    "\n",
    "Begin by writing various helper functions for use in the main loop.\n",
    "Complete the `utils.py` file by following the instructions.\n",
    "\n",
    "*(2.1)* Complete the `prepImage()` function, which is used to prepare the image for inference. The code here should be the exact same as in exercise 1.\n",
    "\n",
    "*(2.2)* In `createExecNetwork()` function, create an instance of IECore object and load the CPU plugin specified by the variable `extension`. The solution is identical to the implementationin exercise 1. Optionally, add a if check to see if \"CPU\" appears in the device list. While it is safe toload the extension even if you are not using CPU, it is a good practice to add a if check to not load unnecessary extensions.\n",
    "\n",
    "*(2.3)* In `createExecNetwork()` function, create an instance of ExecutableNetwork from `ie_net` with the optimal number of requests and return it. The method for this is demonstrated in the slides for video 2 of course 2.\n",
    "\n",
    "*(2.4)* In `setCallbackAndQueue()` function, add a callback function called `callbackFunc` to each of the request slots. We will be defining this function in step (2.5). To do this, first create a dictinary that contains the queue and the request slot id. The key to use for this dictionary is up to you. Then call the  `set_completion_callback()` method for the requests to add the `callbackFun` (note the lack of parethesis). For more details, see the slides for course 2 video 6.\n",
    "\n",
    "*(2.5)* In `callbackFunc()` function, add a tuple containing the request slot ID and the status code for the inference. See the queue usage in `setCallbackAndQueue()` for how to add this tuple. Remember that py_data is the dictionary you passed in in the previoud step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "import cv2\n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "\n",
    "# Prepares image for inference by reshaping and transposing.\n",
    "# inputs:\n",
    "#     orig_image - numpy array containing the original, unprocessed image\n",
    "#     ie_net     - IENetwork object \n",
    "def prepImage(orig_image, ie_net):\n",
    "    \n",
    "    ##! (2.1) Find n, c, h, w from ie_net !##\n",
    "    \n",
    "    input_image = cv2.resize(orig_image, (w, h))\n",
    "    input_image = input_image.transpose((2, 0, 1))\n",
    "    input_image.reshape((n, c, h, w))\n",
    "\n",
    "    return input_image\n",
    "\n",
    "# Processes the result. Returns the number of detected vehices in the image.\n",
    "# inputs:\n",
    "#    detected_obects - numpy array containing the ooutput of the model\n",
    "#    prob_threashold - Required probability for \"detection\"\n",
    "# output:\n",
    "#    Number of vehices detected.\n",
    "def getCount(detected_objects, prob_threshold=0.5):\n",
    "    detected_count = 0\n",
    "    for obj in detected_objects[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > prob_threshold:\n",
    "            detected_count+=1\n",
    "    return detected_count\n",
    "\n",
    "\n",
    "# Create ExecutableNetwork with the optimial number of requests for a given device.\n",
    "# inputs:\n",
    "#    ie_net - IENetwork object to use\n",
    "#    device - String to use for device_name argument.\n",
    "# output:\n",
    "#    ExecutabeNetwork object\n",
    "def createExecNetwork(ie_net, device):\n",
    "    ##! (2.2) Create IECore !##\n",
    "    \n",
    "    ##! (2.2) Load the CPU plugin (optional: check if it is needed)!##\n",
    "    extension = '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so'\n",
    "\n",
    "    ##! (2.3) Create ExecutableNetwork object and find the optimizal number of requests !##\n",
    "\n",
    "    ##! (2.3) Recreate IECore and with num_requests set to optimial number of requests !##\n",
    "    \n",
    "    ##! (2.3) return the ExecutableNetwork !##\n",
    "\n",
    "    \n",
    "# Set callback functions for the inference requests.\n",
    "# inputs:\n",
    "#    exec_net - ExecutableNetwork object to modify\n",
    "#    c_queue  - Python queue to put the slot ID in\n",
    "def setCallbackAndQueue(exec_net, c_queue):\n",
    "    for req_slot in range(len(exec_net.requests)):\n",
    "        ##! (2.4) Create a dictionary for py_data to pass in the queue and ID !###\n",
    "\n",
    "        ##! (2.4) Set the completion callback with the arguments for each reqeust !##\n",
    "        \n",
    "        # Initializing the queue. The second item of the tuple is the status of the previous \n",
    "        #  inference. But as there is no previous inference right now, setting the status to None.\n",
    "        c_queue.put((req_slot, None))\n",
    "    \n",
    "# Callback function called on completion of the inference.\n",
    "# inputs:\n",
    "#    status  - status code for the inference.\n",
    "#    py_data - dictionary arguments passed into the function\n",
    "def callbackFunc(status, py_data):\n",
    "    try:\n",
    "        ##! (2.5) Add a tuple (id, status) to queue here !##\n",
    "    except:\n",
    "        print(\"There was an issue in callback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Main loop\n",
    "\n",
    "Now write the main loop. \n",
    "Complete the `main.py` file by following the instructions.\n",
    "\n",
    "*Note* Many of the variables are already placed and set to None. This is because these variables are used in other parts of the code that have been provided to you. So do not change th name of the variable, but instead replace None with code specified by the instructions.\n",
    "\n",
    "\n",
    "*(3.1)* Create the IENetwork object with FP16 version the `vehicle-detection-adas-0002` model that we have downloaded earlier. Then find the name of the input layer and output layer.\n",
    "\n",
    "*(3.2)* Run the `getCount()` function to get the number of vehicles in the inference result from the slot that completed (`req_slot`). The `getCount()` function takes a numpy array containing the result of the `vehicle-detection-adas-0002` model. Remember that the `output` attribute of the InferRequest object is a dictionary. Refer to exercise 1 for how to get the output of the inference.\n",
    "\n",
    "*(3.3)* Start the next asynchrounus inference on the completed slot (`req_slot`) with `start_async()` method of the ExecutableNetwork. See exercise 1 for how to use `start_async()`.\n",
    "\n",
    "*(3.4)* Repeat step 3.2 again for the edge case handlnig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "import cv2\n",
    "import sys\n",
    "import queue\n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "from utils import *\n",
    "\n",
    "device = sys.argv[1]\n",
    "\n",
    "##! (3.1) Create IENetwork object from vehicle-detection-adas-0002 !##\n",
    "ie_net = None\n",
    "\n",
    "##! (3.1) Get the name of input and output layers. There is only one of each. !##\n",
    "input_layer  = None\n",
    "output_layer = None\n",
    "\n",
    "# Create ExecutableNetwork object using createExecNetwork in utils.py \n",
    "exec_net = createExecNetwork(ie_net, device)\n",
    "print(\"ExecutableNetwork created with {} requests.\".format(len(exec_net.requests)))\n",
    "\n",
    "# Set the callback functions using setCallbackAndQueue() in utils.py \n",
    "c_queue = queue.Queue()\n",
    "setCallbackAndQueue(exec_net, c_queue)\n",
    "\n",
    "# Stats for processing\n",
    "max_vehicles = 0\n",
    "min_vehicles = 999      # this is safe as the max number of detectable objects is 200\n",
    "sum_vehicles = 0\n",
    "num_frames = 0\n",
    "# Loading the data from a video\n",
    "input_video = \"/data/reference-sample-data/object-detection-python/cars_1900.mp4\"\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, next_frame = cap.read()\n",
    "    # Condition for the end of video\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    ##! preprocess next_frame using prepImage from utils.py !##\n",
    "    input_frame = prepImage(next_frame, ie_net) \n",
    "    \n",
    "    # using get to wait for the nextslot ID. Here we are setting a timeout of 30 seconds in case \n",
    "    #  there are issues with the callback and queue never gets populated. With timeout, this function\n",
    "    #  will error out  with \"Empty\"\n",
    "    req_slot, status = c_queue.get(timeout=30)\n",
    "    \n",
    "    if status == 0:\n",
    "        ##! (3.2) Postprocess result from the request slot using getCount function from utils.py !##\n",
    "        num_vehicles = None\n",
    "        \n",
    "        max_vehicles = max(num_vehicles, max_vehicles)\n",
    "        min_vehicles = min(num_vehicles, min_vehicles)\n",
    "        sum_vehicles += num_vehicles\n",
    "        num_frames += 1\n",
    "        \n",
    "    # Recall that None is what we set for the first time initializeation of queue, so we catch everything else.\n",
    "    elif not status is None:\n",
    "        print(\"There was error in processing an image\")\n",
    "\n",
    "    ##! (3.3) Start the next inference on the now open slot. !##\n",
    "    \n",
    "\n",
    "# Handle the remaining images.\n",
    "#  first we wait for all request slots to complete\n",
    "for req in exec_net.requests:\n",
    "    req.wait()\n",
    "\n",
    "# Handle remaining results \n",
    "while not c_queue.empty():\n",
    "    req_slot, status = c_queue.get(timeout=30)\n",
    "    \n",
    "    if status == 0:\n",
    "        ##! (3.4) Postprocess result from the request slot using getCount function from utils.py !##\n",
    "        num_vehicles = None\n",
    "        \n",
    "        max_vehicles = max(num_vehicles, max_vehicles)\n",
    "        min_vehicles = min(num_vehicles, min_vehicles)\n",
    "        sum_vehicles += num_vehicles\n",
    "        \n",
    "    # Recall that None is what we set for the first time initializeation of queue, so we catch everything else.\n",
    "    elif not status is None:\n",
    "        print(\"There was error in processing an image\")\n",
    "        \n",
    "# Finally, reporting results.\n",
    "print(\"Maximum number of cars detected: {}\".format(max_vehicles))\n",
    "print(\"Minimum number of cars detected: {}\".format(min_vehicles))\n",
    "print(\"average number of cars detected: {:.3g}\".format(sum_vehicles/num_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the job\n",
    "\n",
    "Finally, let us try to run the workload. \n",
    "The following code will submit a job to the VPU system. \n",
    "The commands, as well as the utility `waitForJob()` function arethe same as the exercise 1.\n",
    "\n",
    "**Note:** The toolkit is very verbose when using MYRIAD systems, so you may get a lot of additional output beyond what you are expecting. \n",
    "\n",
    "**The final average vehicles detected to the third decimal will be asked in the quiz.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import waitForJob\n",
    "job_name = !echo \"python3 main.py HDDL\" | qsub -d `pwd` -N objdet -l nodes=1:iei-mustang-v100-mx8\n",
    "waitForJob(job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have just ran multiple requests in parallel. \n",
    "From the output, you can see that up to 32 requests could be ran in parallel. \n",
    "Though in practice a fewer number is actually used because the CPU can not keepup with the preprocessing.\n",
    "\n",
    "**The final average vehicles detected to the third decimal will be asked in the quiz.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (sys python)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
